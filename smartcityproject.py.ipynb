{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11879,"sourceType":"datasetVersion","datasetId":8494}],"dockerImageVersionId":30527,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Loading the dataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv(\"/kaggle/input/smart-city-traffic-patterns/train_aWnotuB.csv\")\ndf","metadata":{"execution":{"iopub.status.busy":"2023-08-21T02:54:07.423959Z","iopub.execute_input":"2023-08-21T02:54:07.424956Z","iopub.status.idle":"2023-08-21T02:54:07.529363Z","shell.execute_reply.started":"2023-08-21T02:54:07.424918Z","shell.execute_reply":"2023-08-21T02:54:07.527951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ndf.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.duplicated()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop_duplicates()\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['DateTime'] = pd.to_datetime(df['DateTime'])  \n\ndf['Date'] = df['DateTime'].dt.date\ndf['Time'] = df['DateTime'].dt.time\n\ndf['Date'] = df['Date'].astype(str)\ndf['Time'] = df['Time'].astype(str)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop('DateTime', axis = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Date'] = pd.to_datetime(df['Date'])\n\ndf['DayOfWeek'] = df['Date'].dt.dayofweek\n\ndf['Month'] = df['Date'].dt.month\n\ndf['Year'] = df['Date'].dt.year","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import holidays\ndf['Date'] = pd.to_datetime(df['Date'])\n\nindian_holidays = holidays.India(years=df['Date'].dt.year.unique())\n\n# Custom function to check if the date is a holiday in India\ndef is_holiday_in_india(date):\n    return date in indian_holidays\n\n# Apply the custom function to the 'Date' column\ndf['IsHoliday'] = df['Date'].apply(lambda x: is_holiday_in_india(x))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['IsHoliday'].unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing unnecessary columns\n\ndf = df.drop(['ID'], axis = 1)\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualization \n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\npio.templates.default = \"plotly_white\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.line(df, x='Date', y='Vehicles', title='Traffic Volume over Time')\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Grouping by Junction and looking at the statistical measures\njunction_stats = df.groupby('Junction')['Vehicles'].describe()\nprint(junction_stats)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization","metadata":{}},{"cell_type":"markdown","source":"## Bar plot for junction","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndf.groupby('Junction')['Vehicles'].mean().plot(kind='bar')\nplt.xlabel('Junction')\nplt.ylabel('Average Vehicles')\nplt.title('Average Vehicles by Junction')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Box plot for IsHoliday","metadata":{}},{"cell_type":"code","source":"df.boxplot(column='Vehicles', by='IsHoliday')\nplt.xlabel('Is Holiday')\nplt.ylabel('Vehicles')\nplt.title('Distribution of Vehicles by Holiday')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hypothesis Testing : t-test","metadata":{}},{"cell_type":"code","source":"from scipy.stats import ttest_ind\n\njunction_1 = df[df['Junction'] == 1]['Vehicles']\njunction_2 = df[df['Junction'] == 2]['Vehicles']\n\nt_stat, p_value = ttest_ind(junction_1, junction_2)\nprint(f\"t-statistic: {t_stat}, p-value: {p_value}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This signifies that the t-statistic of 153.93 indicates a substantial difference between the average number of vehicles for the two junctions.\n\n### A p-value of 0.0 indicates an extremely low probability of observing the data under the assumption that there is no difference between the means of the two groups, suggesting that the null hypothesis can be rejected.","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"## Creating lag features to capture any time-dependant features","metadata":{}},{"cell_type":"code","source":"df['PreviousDayVehicles'] = df['Vehicles'].shift(24)\ndf['PreviousHourVehicles'] = df['Vehicles'].shift(1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['PreviousDayVehicles'].fillna(0,inplace = True)\ndf['PreviousHourVehicles'].fillna(0,inplace = True)\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting the Data:\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, test_df = train_test_split(df, test_size=0.2, shuffle=False)\n\n# Printing the sizes of the training and testing sets\nprint(f\"Training set size: {len(train_df)}\")\nprint(f\"Testing set size: {len(test_df)}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling and Evaluation","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.plot(target.index, target.values, label='Historical Traffic', color='b')\nplt.plot(train_forecast_df.index, train_forecast_df['Vehicles'], label='Forecasted Traffic', color='r')\nplt.xlabel('Time')\nplt.ylabel('Traffic (Vehicles)')\nplt.title('Historical and Forecasted Traffic Patterns for the Training Set')\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transitioning to LSTM","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import LSTM, Dense","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n# Converting 'Vehicles' column to float\ndf['Vehicles'] = df['Vehicles'].astype(float)\n\n# Normalizing 'Vehicles' column using MinMaxScaler\nscaler = MinMaxScaler()\ndf[['Vehicles']] = scaler.fit_transform(df[['Vehicles']])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the 'Date' column to numeric features\ndf['Year'] = df['Date'].dt.year\ndf['Month'] = df['Date'].dt.month\ndf['Day'] = df['Date'].dt.day\ndf['Hour'] = df['Date'].dt.hour\n\n# Drop the original 'Date' column since it's no longer needed\ndf.drop(columns=['Date'], inplace=True)\n\n# Check if all columns are now numeric\nprint(df.dtypes)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert 'IsHoliday' column to numeric format\ndf['IsHoliday'] = df['IsHoliday'].astype(int)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\n\nsequence_length = 24 \n\nX_columns = ['Junction', 'Vehicles', 'DayOfWeek', 'Month', 'Year', 'IsHoliday',\n             'PreviousDayVehicles', 'PreviousHourVehicles']\ny_column = 'Vehicles'\n\n# Splitting the data into input sequences (X) and labels (y)\nX = []\ny = []\n\ndata_array = df.values\n\ndata_array = df[X_columns + [y_column]].values\n\nfor i in range(len(data_array) - sequence_length):\n    X.append(data_array[i:i + sequence_length, :-1])  # Exclude last column\n    y.append(data_array[i + sequence_length, -1])  # Last column is target 'Vehicles'\n\nX = np.array(X)\ny = np.array(y)\n\n# Splitting the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Building the LSTM model\nmodel = Sequential()\nmodel.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\nmodel.add(LSTM(units=50))\nmodel.add(Dense(units=1))\n\n# Compiling the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Training the model on the training data\nmodel.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation \n\nloss = model.evaluate(X_test, y_test)\nprint(f\"Test Loss: {loss}\")\n\n# Compare with training loss\ntrain_loss = model.evaluate(X_train, y_train)\nprint(f\"Training Loss: {train_loss}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)\n\n# Reshaping y_pred to a 2D array with shape (num_samples, 1)\ny_pred = y_pred.reshape(-1, 1)\ny_test = y_test.reshape(-1, 1)\n\n\n# Inverse transforming the predicted values to their original scale (if needed)\ny_pred_original = scaler.inverse_transform(y_pred)\n\n# Inverse transforming the actual test target values (y_test) to their original scale\ny_test_original = scaler.inverse_transform(y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing the results: \n\n# Plotting the actual 'Vehicles' values against the predicted values for the test dataset\nplt.figure(figsize=(12, 6))\nplt.plot(y_test_original, label='Actual Vehicles')\nplt.plot(y_pred_original, label='Predicted Vehicles')\nplt.xlabel('Time')\nplt.ylabel('Vehicles')\nplt.title('Actual vs. Predicted Vehicles')\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, mean_squared_error\n\nmae = mean_absolute_error(y_test_original, y_pred_original)\nmse = mean_squared_error(y_test_original, y_pred_original)\nrmse = np.sqrt(mse)\n\nprint(\"Mean Absolute Error (MAE):\", mae)\nprint(\"Mean Squared Error (MSE):\", mse)\nprint(\"Root Mean Squared Error (RMSE):\", rmse)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In conclusion, the LSTM model demonstrates strong predictive capabilities for traffic forecasting. Its accurate predictions and low error metrics make it a valuable tool for traffic management and infrastructure planning in smart cities. However, it's essential to continue monitoring and refining the model regularly to ensure it maintains its accuracy over time and adapts to any changes in traffic patterns or other factors affectingÂ traffic.","metadata":{}},{"cell_type":"markdown","source":"# Analyzing Forecasted Traffic Patterns","metadata":{}},{"cell_type":"markdown","source":"## Plotting the Forecasted vs. Actual Traffic Counts","metadata":{}},{"cell_type":"code","source":"df['DateTime'] = pd.to_datetime(df[['Year', 'Month', 'Day', 'Hour']])\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the timestamp for the test data\ntest_timestamps = df.iloc[-len(y_test_original):]['DateTime']\n\n# Creating a figure and plot the actual traffic counts\nplt.figure(figsize=(12, 6))\nplt.plot(test_timestamps, y_test_original, label='Actual Traffic Counts', color='blue')\n\n# Getting the timestamp for the forecasted data\nforecasted_timestamps = df.iloc[-len(y_test_original):]['DateTime']\n\n# Plotting the predicted traffic counts for the corresponding time period\nplt.plot(forecasted_timestamps, y_pred_original, label='Forecasted Traffic Counts', color='red')\n\nplt.xlabel('Date')\nplt.ylabel('Traffic Counts')\nplt.title('Forecasted vs. Actual Traffic Counts')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since the predicted traffic counts only occupy a small part at the end of the graph, it indicates that the model's predictions are trailing the actual traffic counts for the test dataset.","metadata":{}},{"cell_type":"markdown","source":"## Visualizing Trends","metadata":{}},{"cell_type":"markdown","source":"This plot will help us identify any monthly trends in traffic.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n# Extracting Year and Month from the DateTime column\ndf['Year'] = df['DateTime'].dt.year\ndf['Month'] = df['DateTime'].dt.month\n\n# Grouping the data by Year and Month and calculate the average traffic counts for each month\nmonthly_traffic = df.groupby(['Year', 'Month'])['Vehicles'].mean().reset_index()\n\n# Plotting the average traffic counts by month\nplt.figure(figsize=(10, 6))\nsns.lineplot(x='Month', y='Vehicles', hue='Year', data=monthly_traffic)\nplt.xlabel('Month')\nplt.ylabel('Average Traffic Counts')\nplt.title('Monthly Average Traffic Counts')\nplt.legend(title='Year', loc='upper right')\nplt.grid(True)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Analyzing Seasonal Variations","metadata":{}},{"cell_type":"markdown","source":"This plot with the seasonal decomposition will reveal the seasonal variations and recurring patterns in the forecasted data.","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\n\n# Decomposing the time series into trend, seasonal, and residual components\ndecomposition = sm.tsa.seasonal_decompose(df['Vehicles'], model='additive', period=24*7)  # Assuming a weekly seasonality\n\n# Plotting the components\nplt.figure(figsize=(12, 8))\nplt.subplot(4, 1, 1)\nplt.plot(decomposition.trend)\nplt.ylabel('Trend')\nplt.title('Trend Component')\nplt.grid(True)\n\nplt.subplot(4, 1, 2)\nplt.plot(decomposition.seasonal)\nplt.ylabel('Seasonal')\nplt.title('Seasonal Component')\nplt.grid(True)\n\nplt.subplot(4, 1, 3)\nplt.plot(decomposition.resid)\nplt.ylabel('Residual')\nplt.title('Residual Component')\nplt.grid(True)\n\nplt.subplot(4, 1, 4)\nplt.plot(df['Vehicles'])\nplt.ylabel('Traffic Counts')\nplt.title('Original Data')\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Infrastructure Planning","metadata":{}},{"cell_type":"markdown","source":"## Design a Robust Traffic Management System","metadata":{}},{"cell_type":"markdown","source":"Designing a dynamic traffic management system that adapts to peak traffic hours and efficiently handles the increased load during those hours.","metadata":{}},{"cell_type":"code","source":"df['HourOfDay'] = df['DateTime'].dt.hour\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"peak_traffic_hours = df[(df['HourOfDay'] >= 7) & (df['HourOfDay'] <= 10)]  # Assumed peak traffic hours from 7 AM to 10 AM\n\n# Visualize peak traffic hours\nplt.figure(figsize=(12, 6))\nplt.plot(df['DateTime'], df['Vehicles'], label='Traffic Counts')\nplt.scatter(peak_traffic_hours['DateTime'], peak_traffic_hours['Vehicles'], color='purple', label='Peak Traffic Hours')\nplt.xlabel('Date')\nplt.ylabel('Traffic Counts')\nplt.title('Peak Traffic Hours')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}